Look out for videos of "Luis Serrano". His videos are good about machine learning and deep learning.
 
What is Machine Learning?
Good video - https://www.youtube.com/watch?v=IpGxLWOIZy4
1. Linear Regression - Here using the existing data, we will try to get a line that is closer to the points in the graph with x and y axis. This line can be a straight line or circle or even a wave shape line. Using this line, we can predict the point in graph for data which has x axis value. i.e., For eg. Lets take the real estate case where in we have rate values for few of the houses with different sq.ft values. Have the house area in x axis and its rate in y axis. Using this data, draw a line which is closer to the points in the graph for the available x and y axis values. Now, find out the rate of a house whose area is not available in the available data. During this time, using the line drawn with the given data can get us the corresponding rate value by choosing the respective (x,y) point in the graph. This is Linear regression approach. For this, the challenge is we need to come up with the closest line in the graph for the given data, which will help us in getting the accurate value for any new inputs that are coming up.
How will we get this closest line? This can be achieved by summing up the distance between the line and each (x,y) coordinates in the graph. If the sum value is lesser then the line is closer to the points/coordinates, which will be the best. This approach is called Gradient Descent. i.e., trying with multiple values and coming up with the closest one.
2. Naïve Bayes algorithm - Here, we will analyse the data and come up with the list of features/behaviours which help us in finding the output. Using this collected list, we will try to find the output for any input.
For eg. If we want to find out the spam emails from the inbox then we will need to collect the list of cases which says the email is spam. Like, if the email has a specific keyword or spelling mistake or with no subject then the are spam emails.
3. Decision tree - This is a binary tree which we draw based on the data by applying the conditions and segregate them. For eg. if we have the data like people using different mobile apps. Now with this given data we need to group them based on the app which they use and come up with the tree structure. For eg. if the data is like, less than 20 years old are using facebook, and in >20 years, we see males use whatsapp and females use telegram. This way we can create the tree which can be used to predict the output for any input which comes in.
4. Logistic regression - Here too, we will come up with the line, but to segregate two different types of values. For eg. if we have the list of points in graph falling under two categories - Correct and wrong. Then we will come up with a line which can segregate these two values and so for any incoming value, if its point fall under correct area then it will be a correct else wrong value. So, how do we come up with the correct line that segregates correctly? The line should intersect in such a way that the average distance between closest correct values and closest wrong values to the line should be same or closer. This approach is called Linear optimization.
But here too, some times single line will not be sufficient to segregate the two categories. So, we may need to go with more than one lines to arrive at the area segregation. This is called neural networks. Because we will combine the output of multiple lines and arrive at the correct area segregation. In brain, the similar action will be performed like the output of multiple neurons will be collected by another neuron and arrives at a final output.
5. Kernel Trick - this approach will be taken when both the correct and wrong values are in the same straight line. And so only a curve line should be drawn to segregate them. Or even if it is 3-dimensional graph then we need to get an intermediate plate to differentiate both correct and wrong values. This will be done by identifying some mathematical calculation which can segregate the correct and wrong values. Like x+y or x*y or x^2 or y^2. Out of these calculation any one would get us the values to easily segregate the categories. This is called support vector machine Kernel trick.
6. K-Means Clustering algorithm - This will be applied in cases where we need to find out the right location to place the given input. For eg. in a residential area we need to find out the location where we can place the pizza shop which should be easily accessible by many. We need to try out multiple options by placing the pizza shop location and understand how many houses can easily access. Based on that value we will arrive at the correct location.
7. Hierarchical clustering - Here we will try to find the closest houses and form a cluster. With that info will suggest where to place the pizza shop near by.